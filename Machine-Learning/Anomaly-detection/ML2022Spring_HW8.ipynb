{"cells":[{"cell_type":"markdown","metadata":{"id":"YiVfKn-6tXz8"},"source":["# **Homework 8 - Anomaly Detection**\n","\n","If there are any questions, please contact mlta-2022spring-ta@googlegroups.com\n","\n","Slide:    [Link]()　Kaggle: [Link](https://www.kaggle.com/c/ml2022spring-hw8)"]},{"cell_type":"markdown","metadata":{"id":"bDk9r2YOcDc9"},"source":["# Set up the environment\n"]},{"cell_type":"markdown","metadata":{"id":"Oi12tJMYWi0Q"},"source":["## Package installation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7807,"status":"ok","timestamp":1694947104752,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"7LexxyPWWjJB","outputId":"e0607db2-77a6-4ad0-e471-623702ba6225"},"outputs":[],"source":["# Training progress bar\n","!pip install -q qqdm"]},{"cell_type":"markdown","metadata":{"id":"DCgNXSsEWuY7"},"source":["## Downloading data"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51669,"status":"ok","timestamp":1694947156417,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"0K5kmlkuWzhJ","outputId":"7136f453-333e-42e2-e507-b9258468d07f"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# !unzip '/content/drive/MyDrive/Lab Training ML/Assignment 8/data.zip'"]},{"cell_type":"markdown","metadata":{"id":"HNe7QU7n7cqh"},"source":["# Import packages"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4899,"status":"ok","timestamp":1694947161313,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"Jk3qFK_a7k8P"},"outputs":[],"source":["import random\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torchvision.models as models\n","from torch.optim import Adam, AdamW\n","from qqdm import qqdm, format_str\n","import pandas as pd\n"]},{"cell_type":"markdown","metadata":{"id":"6X6fkGPnYyaF"},"source":["# Loading data"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":512,"status":"ok","timestamp":1694947161823,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"k7Wd4yiUYzAm","outputId":"bfe45ed7-5db3-48e8-d801-cee7b0dfbd8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["(100000, 64, 64, 3)\n","(19636, 64, 64, 3)\n"]}],"source":["train = np.load(\"data/trainingset.npy\", allow_pickle=True)\n","test = np.load(\"data/testingset.npy\", allow_pickle=True)\n","\n","print(train.shape)\n","print(test.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"_flpmj6OYIa6"},"source":["## Random seed\n","Set the random seed to a certain value for reproducibility."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1694947161823,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"Gb-dgXQYYI2Q"},"outputs":[],"source":["def same_seeds(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","\n","same_seeds(48763)\n"]},{"cell_type":"markdown","metadata":{"id":"zR9zC0_Df-CR"},"source":["# Autoencoder"]},{"cell_type":"markdown","metadata":{"id":"1EbfwRREhA7c"},"source":["# Models & loss"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":677,"status":"ok","timestamp":1694947178230,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"Wi8ds1fugCkR"},"outputs":[],"source":["class fcn_autoencoder(nn.Module):\n","    def __init__(self):\n","        super(fcn_autoencoder, self).__init__()\n","        self.encoder1 = nn.Sequential(\n","            nn.Linear(64 * 64 * 3, 4096),\n","            nn.ReLU(),\n","            nn.Linear(4096, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 64),\n","        )\n","\n","        self.encoder2 = nn.Sequential(\n","            nn.Linear(64 * 64 * 3, 2048),\n","            nn.ReLU(),\n","            nn.Linear(2048, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 64),\n","        )\n","\n","        self.encoder3 = nn.Sequential(\n","            nn.Linear(64 * 64 * 3, 3200),\n","            nn.ReLU(),\n","            nn.Linear(3200, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 64),\n","        )\n","\n","        self.decoder = nn.Sequential(\n","            nn.Linear(64, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 4096),\n","            nn.ReLU(),\n","            nn.Linear(4096, 64 * 64 * 3),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        x1 = self.encoder1(x)\n","        x2 = self.encoder2(x)\n","        x3 = self.encoder3(x)\n","        noise = (0.1**0.5) * torch.randn(x1.shape).cuda()\n","        out = self.decoder(x1 + x2 + x3 + noise)\n","        return out\n","\n","\n","class conv_autoencoder(nn.Module):\n","    def __init__(self):\n","        super(conv_autoencoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 12, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(12, 24, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","\n","\n","class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 12, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(12, 24, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","        self.enc_out_1 = nn.Sequential(\n","            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","        self.enc_out_2 = nn.Sequential(\n","            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n","            nn.Tanh(),\n","        )\n","\n","    def encode(self, x):\n","        h1 = self.encoder(x)\n","        return self.enc_out_1(h1), self.enc_out_2(h1)\n","\n","    def reparametrize(self, mu, logvar):\n","        std = logvar.mul(0.5).exp_()\n","        if torch.cuda.is_available():\n","            eps = torch.cuda.FloatTensor(std.size()).normal_()\n","        else:\n","            eps = torch.FloatTensor(std.size()).normal_()\n","        eps = Variable(eps)\n","        return eps.mul(std).add_(mu)\n","\n","    def decode(self, z):\n","        return self.decoder(z)\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparametrize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","\n","\n","def loss_vae(recon_x, x, mu, logvar, criterion):\n","    \"\"\"\n","    recon_x: generating images\n","    x: origin images\n","    mu: latent mean\n","    logvar: latent log variance\n","    \"\"\"\n","    mse = criterion(recon_x, x)\n","    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n","    KLD = torch.sum(KLD_element).mul_(-0.5)\n","    return mse + KLD\n"]},{"cell_type":"markdown","metadata":{"id":"vrJ9bScg9AgO"},"source":["# Dataset module\n","\n","Module for obtaining and processing data. The transform function here normalizes image's pixels from [0, 255] to [-1.0, 1.0].\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1694947178674,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"33fWhE-h9LPq"},"outputs":[],"source":["class CustomTensorDataset(TensorDataset):\n","    \"\"\"TensorDataset with support of transforms.\"\"\"\n","\n","    def __init__(self, tensors):\n","        self.tensors = tensors\n","        if tensors.shape[-1] == 3:\n","            self.tensors = tensors.permute(0, 3, 1, 2)\n","\n","        self.transform = transforms.Compose(\n","            [\n","                transforms.Lambda(lambda x: x.to(torch.float32)),\n","                transforms.Lambda(lambda x: 2.0 * x / 255.0 - 1.0),\n","            ]\n","        )\n","\n","    def __getitem__(self, index):\n","        x = self.tensors[index]\n","\n","        if self.transform:\n","            # mapping images to [-1.0, 1.0]\n","            x = self.transform(x)\n","\n","        return x\n","\n","    def __len__(self):\n","        return len(self.tensors)\n"]},{"cell_type":"markdown","metadata":{"id":"XKNUImqUhIeq"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"7ebAJdjFmS08"},"source":["## Configuration\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6329,"status":"ok","timestamp":1694947185001,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"in7yLfmqtZTk"},"outputs":[],"source":["# Training hyperparameters\n","num_epochs = 100\n","batch_size = 256\n","learning_rate = 5e-4\n","\n","# Build training dataloader\n","x = torch.from_numpy(train)\n","train_dataset = CustomTensorDataset(x)\n","\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n","\n","# Model\n","model_type = \"fcn\"  # selecting a model type from {'cnn', 'fcn', 'vae', 'resnet'}\n","model_classes = {\"fcn\": fcn_autoencoder(), \"cnn\": conv_autoencoder(), \"vae\": VAE()}\n","model = model_classes[model_type].cuda()\n","\n","# Loss and optimizer\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"]},{"cell_type":"markdown","metadata":{"id":"wyooN-JPm8sS"},"source":["## Training loop"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6298440,"status":"ok","timestamp":1694953483438,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"JoW1UrrxgI_U","outputId":"7a58d839-a143-40b1-cb5c-fd2c60fd0154"},"outputs":[{"name":"stderr","output_type":"stream","text":[" \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m                                               \n"," \u001b[99m0/\u001b[93m100\u001b[0m\u001b[0m  \u001b[99m        -        \u001b[0m  \u001b[99m   -    \u001b[0m                                             \n","\u001b[1mDescription\u001b[0m   0.0% |                                                           |\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m                                               \n"," \u001b[99m0/\u001b[93m100\u001b[0m\u001b[0m  \u001b[99m        -        \u001b[0m  \u001b[99m   -    \u001b[0m                                             \n","\u001b[1mDescription\u001b[0m   0.0% |                                                           |"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 4.00 GiB total capacity; 3.38 GiB already allocated; 0 bytes free; 3.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[1;32md:\\NYCU CS\\Lab-training\\Machine-Learning\\Anomaly-detection\\ML2022Spring_HW8.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NYCU%20CS/Lab-training/Machine-Learning/Anomaly-detection/ML2022Spring_HW8.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NYCU%20CS/Lab-training/Machine-Learning/Anomaly-detection/ML2022Spring_HW8.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/NYCU%20CS/Lab-training/Machine-Learning/Anomaly-detection/ML2022Spring_HW8.ipynb#X30sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NYCU%20CS/Lab-training/Machine-Learning/Anomaly-detection/ML2022Spring_HW8.ipynb#X30sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# ===================save_best====================\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NYCU%20CS/Lab-training/Machine-Learning/Anomaly-detection/ML2022Spring_HW8.ipynb#X30sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m mean_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(tot_loss)\n","File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n","File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     adam(\n\u001b[0;32m    142\u001b[0m         params_with_grad,\n\u001b[0;32m    143\u001b[0m         grads,\n\u001b[0;32m    144\u001b[0m         exp_avgs,\n\u001b[0;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    147\u001b[0m         state_steps,\n\u001b[0;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n","File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m func(params,\n\u001b[0;32m    282\u001b[0m      grads,\n\u001b[0;32m    283\u001b[0m      exp_avgs,\n\u001b[0;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    286\u001b[0m      state_steps,\n\u001b[0;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n","File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adam.py:507\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    505\u001b[0m     exp_avg_sq_sqrt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_foreach_sqrt(device_exp_avg_sqs)\n\u001b[0;32m    506\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m--> 507\u001b[0m     denom \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_foreach_add(exp_avg_sq_sqrt, eps)\n\u001b[0;32m    509\u001b[0m torch\u001b[39m.\u001b[39m_foreach_addcdiv_(params_, device_exp_avgs, denom, step_size)\n","\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 4.00 GiB total capacity; 3.38 GiB already allocated; 0 bytes free; 3.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["best_loss = np.inf\n","model.train()\n","\n","qqdm_train = qqdm(range(num_epochs), desc=format_str(\"bold\", \"Description\"))\n","for epoch in qqdm_train:\n","    tot_loss = list()\n","    for data in train_dataloader:\n","        # ===================loading=====================\n","        img = data.float().cuda()\n","        if model_type in [\"fcn\"]:\n","            img = img.view(img.shape[0], -1)\n","\n","        # ===================forward=====================\n","        output = model(img)\n","        if model_type in [\"vae\"]:\n","            loss = loss_vae(output[0], img, output[1], output[2], criterion)\n","        else:\n","            loss = criterion(output, img)\n","\n","        tot_loss.append(loss.item())\n","        # ===================backward====================\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    # ===================save_best====================\n","    mean_loss = np.mean(tot_loss)\n","    if mean_loss < best_loss:\n","        best_loss = mean_loss\n","        torch.save(model, \"best_model_{}.pt\".format(model_type))\n","    # ===================log========================\n","    qqdm_train.set_infos(\n","        {\n","            \"epoch\": f\"{epoch + 1:.0f}/{num_epochs:.0f}\",\n","            \"loss\": f\"{mean_loss:.4f}\",\n","        }\n","    )\n","    # ===================save_last========================\n","    torch.save(model, \"last_model_{}.pt\".format(model_type))\n"]},{"cell_type":"markdown","metadata":{"id":"Wk0UxFuchLzR"},"source":["# Inference\n","Model is loaded and generates its anomaly score predictions."]},{"cell_type":"markdown","metadata":{"id":"evgMW3OwoGqD"},"source":["## Initialize\n","- dataloader\n","- model\n","- prediction file"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1122,"status":"ok","timestamp":1694953484556,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"_MBnXAswoKmq"},"outputs":[],"source":["eval_batch_size = 200\n","\n","# build testing dataloader\n","data = torch.tensor(test, dtype=torch.float32)\n","test_dataset = CustomTensorDataset(data)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=eval_batch_size, num_workers=1)\n","eval_loss = nn.MSELoss(reduction=\"none\")\n","\n","# load trained model\n","checkpoint_path = f\"last_model_{model_type}.pt\"\n","model = torch.load(checkpoint_path)\n","model.eval()\n","\n","# prediction file\n","out_file = \"prediction.csv\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3614,"status":"ok","timestamp":1694953488165,"user":{"displayName":"蔡師睿","userId":"00434487390779382774"},"user_tz":-480},"id":"_1IxCX2iCW6V"},"outputs":[],"source":["anomality = list()\n","with torch.no_grad():\n","    for i, data in enumerate(test_dataloader):\n","        img = data.float().cuda()\n","        if model_type in [\"fcn\"]:\n","            img = img.view(img.shape[0], -1)\n","        output = model(img)\n","        if model_type in [\"vae\"]:\n","            output = output[0]\n","        if model_type in [\"fcn\"]:\n","            loss = eval_loss(output, img).sum(-1)\n","        else:\n","            loss = eval_loss(output, img).sum([1, 2, 3])\n","        anomality.append(loss)\n","anomality = torch.cat(anomality, axis=0)\n","anomality = torch.sqrt(anomality).reshape(len(test), 1).cpu().numpy()\n","\n","df = pd.DataFrame(anomality, columns=[\"score\"])\n","df.to_csv(out_file, index_label=\"ID\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
